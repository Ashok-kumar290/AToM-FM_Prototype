{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AToM-FM: Adaptive Transformer of Multimodal Foundation Model\n",
    "## Qwen2.5 Fine-Tuning with QLoRA on RTX 4060 Ti\n",
    "\n",
    "This notebook provides a **complete interactive environment** for:\n",
    "1. Environment setup and GPU verification\n",
    "2. Model loading with 4-bit quantization (QLoRA)\n",
    "3. Dataset preparation and formatting\n",
    "4. Training with SFTTrainer\n",
    "5. Evaluation and inference\n",
    "6. Model export and merging\n",
    "\n",
    "**Hardware Target:** NVIDIA RTX 4060 Ti (8GB/16GB VRAM)  \n",
    "**Model:** Qwen/Qwen2.5-3B (Optimized for Accuracy) with QLoRA adapters  \n",
    "**Dataset:** tatsu-lab/alpaca (52K instruction samples)  \\n**Optimization:** Sequence Packing enabled (~2x faster)  \\n**Optimization:** Sequence Packing enabled (~2x faster)  \\n**Optimization:** Sequence Packing enabled (~2x faster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Requirement already satisfied: torch in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: torchvision in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.20.1+cu121)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: filelock in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (2025.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchvision) (2.4.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchvision) (12.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch) (3.0.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 26.0\n",
      "[notice] To update, run: C:\\Users\\Harsha\\AppData\\Local\\Programs\\Python\\Python311\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (5.0.0)\n",
      "Requirement already satisfied: datasets in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.5.0)\n",
      "Requirement already satisfied: accelerate in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.12.0)\n",
      "Requirement already satisfied: peft in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.18.1)\n",
      "Requirement already satisfied: trl in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.27.1)\n",
      "Requirement already satisfied: bitsandbytes in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.49.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=1.3.0 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (1.3.7)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2.4.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2026.1.15)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: typer-slim in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (4.67.2)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (23.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (2.3.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (2.32.5)\n",
      "Requirement already satisfied: httpx<1.0.0 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (0.70.18)\n",
      "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.10.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate) (7.2.1)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate) (2.5.1+cu121)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.3)\n",
      "Requirement already satisfied: anyio in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1.0.0->datasets) (4.12.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1.0.0->datasets) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1.0.0->datasets) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: shellingham in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (1.5.4)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.32.2->datasets) (2.6.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->datasets) (2025.3)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typer-slim->transformers) (8.3.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 26.0\n",
      "[notice] To update, run: C:\\Users\\Harsha\\AppData\\Local\\Programs\\Python\\Python311\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.24.1)\n",
      "Requirement already satisfied: tensorboard in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.20.0)\n",
      "Requirement already satisfied: evaluate in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.4.6)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.2.1)\n",
      "Requirement already satisfied: click>=8.0.1 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wandb) (8.3.1)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wandb) (3.1.46)\n",
      "Requirement already satisfied: packaging in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wandb) (25.0)\n",
      "Requirement already satisfied: platformdirs in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wandb) (4.5.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wandb) (6.33.5)\n",
      "Requirement already satisfied: pydantic<3 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wandb) (2.12.5)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wandb) (6.0.3)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wandb) (2.32.5)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wandb) (2.51.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.8 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wandb) (4.15.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard) (2.4.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard) (1.76.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard) (3.10.1)\n",
      "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard) (2.4.0)\n",
      "Requirement already satisfied: pillow in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard) (12.0.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard) (65.5.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard) (3.1.5)\n",
      "Requirement already satisfied: datasets>=2.0.0 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from evaluate) (4.5.0)\n",
      "Requirement already satisfied: dill in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from evaluate) (0.4.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from evaluate) (2.3.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from evaluate) (4.67.2)\n",
      "Requirement already satisfied: xxhash in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from evaluate) (3.6.0)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from evaluate) (0.70.18)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.10.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from evaluate) (1.3.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from click>=8.0.1->wandb) (0.4.6)\n",
      "Requirement already satisfied: filelock in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets>=2.0.0->evaluate) (3.20.0)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets>=2.0.0->evaluate) (23.0.0)\n",
      "Requirement already satisfied: httpx<1.0.0 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets>=2.0.0->evaluate) (0.28.1)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fsspec[http]>=2021.05.0->evaluate) (3.13.3)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.7.0->evaluate) (1.2.0)\n",
      "Requirement already satisfied: shellingham in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.7.0->evaluate) (1.5.4)\n",
      "Requirement already satisfied: typer-slim in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.7.0->evaluate) (0.21.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3->wandb) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3->wandb) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2.6.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2025.11.12)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard) (3.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->evaluate) (2025.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.7.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.22.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
      "Requirement already satisfied: anyio in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (4.12.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx<1.0.0->datasets>=2.0.0->evaluate) (0.16.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 26.0\n",
      "[notice] To update, run: C:\\Users\\Harsha\\AppData\\Local\\Programs\\Python\\Python311\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyyaml in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (6.0.3)\n",
      "Requirement already satisfied: omegaconf in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.3.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.10.8)\n",
      "Requirement already satisfied: seaborn in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from omegaconf) (4.9.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (2.4.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (3.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from seaborn) (2.3.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 26.0\n",
      "[notice] To update, run: C:\\Users\\Harsha\\AppData\\Local\\Programs\\Python\\Python311\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.24.1)\n",
      "Requirement already satisfied: click>=8.0.1 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wandb) (8.3.1)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wandb) (3.1.46)\n",
      "Requirement already satisfied: packaging in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wandb) (25.0)\n",
      "Requirement already satisfied: platformdirs in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wandb) (4.5.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wandb) (6.33.5)\n",
      "Requirement already satisfied: pydantic<3 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wandb) (2.12.5)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wandb) (6.0.3)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wandb) (2.32.5)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wandb) (2.51.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.8 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wandb) (4.15.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from click>=8.0.1->wandb) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3->wandb) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3->wandb) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2.6.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2025.11.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 26.0\n",
      "[notice] To update, run: C:\\Users\\Harsha\\AppData\\Local\\Programs\\Python\\Python311\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies (run once)\n",
    "# Uncomment and run if needed:\n",
    "\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "!pip install transformers datasets accelerate peft trl bitsandbytes\n",
    "!pip install wandb tensorboard evaluate sentencepiece\n",
    "!pip install pyyaml omegaconf matplotlib seaborn\n",
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement torch (from versions: none)\n",
      "\n",
      "[notice] A new release of pip is available: 25.3 -> 26.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: No matching distribution found for torch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m [wandb.login()] Changing session credentials to explicit value for https://api.wandb.ai.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: C:\\Users\\Harsha\\_netrc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- AToM-FM Environment Setup ---\n",
    "# Run this cell to ensure all dependencies are installed for the notebook kernel\n",
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "%pip install transformers datasets accelerate peft trl bitsandbytes wandb pyyaml\n",
    "\n",
    "# Login to Weights & Biases\n",
    "import wandb\n",
    "wandb.login(key=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login to Weights & Biases (Optimized for monitoring)\n",
    "%pip install wandb\n",
    "import wandb\n",
    "wandb.login(key=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.24.1)\n",
      "Requirement already satisfied: click>=8.0.1 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wandb) (8.3.1)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wandb) (3.1.46)\n",
      "Requirement already satisfied: packaging in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wandb) (25.0)\n",
      "Requirement already satisfied: platformdirs in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wandb) (4.5.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wandb) (6.33.5)\n",
      "Requirement already satisfied: pydantic<3 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wandb) (2.12.5)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wandb) (6.0.3)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wandb) (2.32.5)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wandb) (2.51.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.8 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wandb) (4.15.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from click>=8.0.1->wandb) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3->wandb) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3->wandb) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2.6.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2025.11.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\harsha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 26.0\n",
      "[notice] To update, run: C:\\Users\\Harsha\\AppData\\Local\\Programs\\Python\\Python311\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wandb'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Login to Weights & Biases (Optimized for monitoring)\u001b[39;00m\n\u001b[32m      2\u001b[39m get_ipython().system(\u001b[33m'\u001b[39m\u001b[33mpip install wandb\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwandb\u001b[39;00m\n\u001b[32m      4\u001b[39m wandb.login(key=\u001b[33m\"\u001b[39m\u001b[33mwandb_v1_9ZKh16POajBEeVTRnzal0ogov1N_LN7jRH7A1AjH5xUggohHRsqSUbN4aVdkmPyS1Bc7Pxx1D70ZA\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'wandb'"
     ]
    }
   ],
   "source": [
    "# Login to Weights & Biases (Optimized for monitoring)\n",
    "!pip install wandb\n",
    "import wandb\n",
    "wandb.login(key=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "PROJECT_ROOT = Path(os.getcwd()).parent\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "os.chdir(PROJECT_ROOT)\n",
    "print(f\"Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "import peft\n",
    "import datasets\n",
    "import trl\n",
    "import bitsandbytes\n",
    "\n",
    "print(f\"Python:        {sys.version}\")\n",
    "print(f\"PyTorch:       {torch.__version__}\")\n",
    "print(f\"Transformers:  {transformers.__version__}\")\n",
    "print(f\"PEFT:          {peft.__version__}\")\n",
    "print(f\"Datasets:      {datasets.__version__}\")\n",
    "print(f\"TRL:           {trl.__version__}\")\n",
    "print(f\"BitsAndBytes:  {bitsandbytes.__version__}\")\n",
    "print(f\"CUDA:          {torch.version.cuda}\")\n",
    "print(f\"GPU:           {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'N/A'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. GPU Verification & VRAM Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import print_gpu_info, print_vram_usage, set_seed, setup_logging\n",
    "\n",
    "setup_logging()\n",
    "set_seed(42)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"  GPU Information\")\n",
    "print(\"=\" * 50)\n",
    "gpu_info = print_gpu_info()\n",
    "print()\n",
    "print_vram_usage()\n",
    "\n",
    "# Determine recommended settings based on VRAM\n",
    "if gpu_info.get(\"vram_total_gb\", 0) >= 16:\n",
    "    print(\"\\n>> 16GB VRAM: Can use Qwen2.5-3B or even 7B with QLoRA\")\n",
    "elif gpu_info.get(\"vram_total_gb\", 0) >= 8:\n",
    "    print(\"\\n>> 8GB VRAM: Recommended Qwen2.5-1.5B with QLoRA (default config)\")\n",
    "else:\n",
    "    print(\"\\n>> <8GB VRAM: Use Qwen2.5-0.5B with QLoRA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Configuration\n",
    "\n",
    "You can either load from YAML files or define inline. We'll do both for flexibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import load_config\n",
    "\n",
    "# Option A: Load from YAML config files\n",
    "config = load_config(\"config\")\n",
    "\n",
    "# Option B: Override specific settings inline\n",
    "# Uncomment any of these to override:\n",
    "\n",
    "# config[\"model\"][\"name\"] = \"Qwen/Qwen2.5-0.5B\"     # smaller model for testing\n",
    "# config[\"model\"][\"name\"] = \"Qwen/Qwen2.5-3B\"        # larger model (needs 8GB+)\n",
    "# config[\"training\"][\"num_train_epochs\"] = 1           # quick test\n",
    "# config[\"training\"][\"max_steps\"] = 100                # very quick test\n",
    "# config[\"training\"][\"per_device_train_batch_size\"] = 1 # reduce if OOM\n",
    "# config[\"model\"][\"lora\"][\"r\"] = 32                    # reduce LoRA rank if OOM\n",
    "# config[\"model\"][\"tokenizer\"][\"max_length\"] = 1024    # reduce seq length if OOM\n",
    "\n",
    "print(\"Model:\", config[\"model\"][\"name\"])\n",
    "print(\"LoRA rank:\", config[\"model\"][\"lora\"][\"r\"])\n",
    "print(\"Epochs:\", config[\"training\"][\"num_train_epochs\"])\n",
    "print(\"Batch size:\", config[\"training\"][\"per_device_train_batch_size\"])\n",
    "print(\"Grad accum:\", config[\"training\"][\"gradient_accumulation_steps\"])\n",
    "print(\"Effective batch:\", config[\"training\"][\"per_device_train_batch_size\"] * config[\"training\"][\"gradient_accumulation_steps\"])\n",
    "print(\"Learning rate:\", config[\"training\"][\"learning_rate\"])\n",
    "print(\"Max seq length:\", config[\"sft\"][\"max_seq_length\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Load Model with QLoRA\n",
    "\n",
    "This loads the Qwen model in 4-bit precision and applies LoRA adapters.\n",
    "Only the LoRA parameters (~1-3% of total) are trainable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model import build_model_and_tokenizer, print_model_summary\n",
    "\n",
    "print(\"Loading model and tokenizer...\")\n",
    "print(f\"Model: {config['model']['name']}\")\n",
    "print(f\"Quantization: 4-bit NF4 with double quantization\")\n",
    "print(f\"LoRA rank: {config['model']['lora']['r']}\")\n",
    "print()\n",
    "\n",
    "model, tokenizer = build_model_and_tokenizer(config)\n",
    "\n",
    "print()\n",
    "print_model_summary(model)\n",
    "print()\n",
    "print_vram_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect LoRA adapter layers\n",
    "print(\"LoRA adapter layers:\")\n",
    "print(\"=\" * 60)\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"  {name:60s} | shape: {str(list(param.shape)):20s} | params: {param.numel():,}\")\n",
    "\n",
    "trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "total = sum(p.numel() for p in model.parameters())\n",
    "print(f\"\\nTrainable: {trainable:,} / {total:,} = {100*trainable/total:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Dataset Preparation\n",
    "\n",
    "Default dataset: **tatsu-lab/alpaca** (52K instruction-following samples)  \n",
    "Format: `{instruction, input, output}` â†’ formatted prompt text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataset import prepare_datasets, format_instruction\n",
    "\n",
    "print(f\"Loading dataset: {config['dataset']['name']}\")\n",
    "train_dataset, eval_dataset = prepare_datasets(config)\n",
    "\n",
    "print(f\"\\nTrain samples: {len(train_dataset):,}\")\n",
    "print(f\"Eval samples:  {len(eval_dataset):,}\")\n",
    "print(f\"Columns: {train_dataset.column_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect a few formatted samples\n",
    "print(\"=\" * 60)\n",
    "print(\"Sample 1:\")\n",
    "print(\"=\" * 60)\n",
    "print(train_dataset[0][\"text\"][:800])\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Sample 2:\")\n",
    "print(\"=\" * 60)\n",
    "print(train_dataset[1][\"text\"][:800])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze token lengths to understand memory requirements\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Sample 1000 examples for length analysis\n",
    "sample_size = min(1000, len(train_dataset))\n",
    "sample_texts = [train_dataset[i][\"text\"] for i in range(sample_size)]\n",
    "token_lengths = [len(tokenizer.encode(t)) for t in sample_texts]\n",
    "\n",
    "print(f\"Token length statistics (sample of {sample_size}):\")\n",
    "print(f\"  Min:    {min(token_lengths)}\")\n",
    "print(f\"  Max:    {max(token_lengths)}\")\n",
    "print(f\"  Mean:   {np.mean(token_lengths):.0f}\")\n",
    "print(f\"  Median: {np.median(token_lengths):.0f}\")\n",
    "print(f\"  95th %%: {np.percentile(token_lengths, 95):.0f}\")\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.hist(token_lengths, bins=50, edgecolor='black', alpha=0.7)\n",
    "plt.axvline(x=config['sft']['max_seq_length'], color='red', linestyle='--', label=f\"max_seq_length={config['sft']['max_seq_length']}\")\n",
    "plt.xlabel('Token Length')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Token Lengths in Training Data')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Training\n",
    "\n",
    "Using `SFTTrainer` from TRL with:\n",
    "- QLoRA (4-bit base + LoRA adapters)\n",
    "- Gradient checkpointing (saves ~40% VRAM)\n",
    "- Paged AdamW 8-bit optimizer\n",
    "- NEFTune noise (improves instruction following)\n",
    "- Cosine LR schedule with warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.trainer import create_trainer\n",
    "\n",
    "trainer = create_trainer(model, tokenizer, train_dataset, eval_dataset, config)\n",
    "\n",
    "print(\"Trainer created!\")\n",
    "print(f\"  Total training steps: {trainer.state.max_steps if trainer.state.max_steps > 0 else 'auto'}\")\n",
    "print(f\"  Effective batch size: {config['training']['per_device_train_batch_size'] * config['training']['gradient_accumulation_steps']}\")\n",
    "print()\n",
    "print_vram_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# START TRAINING\n",
    "# ==========================================\n",
    "# This is the main training cell. On RTX 4060 Ti with Qwen2.5-1.5B:\n",
    "#   - ~3 epochs on Alpaca (52K samples) takes roughly 2-4 hours\n",
    "#   - VRAM usage: ~6-7 GB with default settings\n",
    "#   - If you get OOM, reduce batch_size to 1 or max_seq_length to 1024\n",
    "\n",
    "print(\"Starting training...\")\n",
    "print(\"=\" * 60)\n",
    "print_vram_usage()\n",
    "print(\"=\" * 60)\n",
    "\n",
    "train_result = trainer.train()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Training Complete!\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Metrics: {train_result.metrics}\")\n",
    "print_vram_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training loss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "log_history = trainer.state.log_history\n",
    "\n",
    "train_losses = [(h[\"step\"], h[\"loss\"]) for h in log_history if \"loss\" in h]\n",
    "eval_losses = [(h[\"step\"], h[\"eval_loss\"]) for h in log_history if \"eval_loss\" in h]\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "\n",
    "if train_losses:\n",
    "    steps, losses = zip(*train_losses)\n",
    "    ax.plot(steps, losses, label=\"Train Loss\", alpha=0.7)\n",
    "\n",
    "if eval_losses:\n",
    "    steps, losses = zip(*eval_losses)\n",
    "    ax.plot(steps, losses, label=\"Eval Loss\", marker='o', markersize=4)\n",
    "\n",
    "ax.set_xlabel(\"Step\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.set_title(\"AToM-FM Training Progress\")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the fine-tuned LoRA adapter\n",
    "SAVE_DIR = \"./models/final\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "trainer.save_model(SAVE_DIR)\n",
    "tokenizer.save_pretrained(SAVE_DIR)\n",
    "\n",
    "print(f\"Model saved to: {SAVE_DIR}\")\n",
    "print(f\"Contents:\")\n",
    "for f in sorted(Path(SAVE_DIR).glob(\"*\")):\n",
    "    size_mb = f.stat().st_size / 1e6\n",
    "    print(f\"  {f.name:40s} {size_mb:8.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run evaluation on the eval set\n",
    "eval_metrics = trainer.evaluate()\n",
    "\n",
    "print(\"Evaluation Results:\")\n",
    "print(\"=\" * 40)\n",
    "for key, value in eval_metrics.items():\n",
    "    print(f\"  {key:30s}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Inference & Testing\n",
    "\n",
    "Test the fine-tuned model with various prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference import generate_response\n",
    "\n",
    "def test_prompt(instruction, input_text=\"\", max_new_tokens=256):\n",
    "    \"\"\"Helper to test a prompt and display results.\"\"\"\n",
    "    print(f\"Instruction: {instruction}\")\n",
    "    if input_text:\n",
    "        print(f\"Input: {input_text}\")\n",
    "    print(\"-\" * 40)\n",
    "    response = generate_response(\n",
    "        model, tokenizer, instruction, input_text,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "    )\n",
    "    print(f\"Response: {response}\")\n",
    "    print(\"=\" * 60)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Suite\n",
    "test_cases = [\n",
    "    {\n",
    "        \"instruction\": \"Explain what a neural network is in simple terms.\",\n",
    "        \"input\": \"\",\n",
    "    },\n",
    "    {\n",
    "        \"instruction\": \"Write a Python function to check if a string is a palindrome.\",\n",
    "        \"input\": \"\",\n",
    "    },\n",
    "    {\n",
    "        \"instruction\": \"Summarize the following text.\",\n",
    "        \"input\": \"Machine learning is a subset of artificial intelligence that focuses on building systems that learn from data. Instead of being explicitly programmed, these systems use algorithms to identify patterns in data and make decisions with minimal human intervention. The field has seen tremendous growth in recent years, driven by the availability of large datasets and powerful computing resources.\",\n",
    "    },\n",
    "    {\n",
    "        \"instruction\": \"Translate the following English text to French.\",\n",
    "        \"input\": \"The weather is beautiful today and I want to go for a walk in the park.\",\n",
    "    },\n",
    "    {\n",
    "        \"instruction\": \"What are the three laws of thermodynamics? Explain each briefly.\",\n",
    "        \"input\": \"\",\n",
    "    },\n",
    "]\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"  AToM-FM Test Suite\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "responses = []\n",
    "for i, tc in enumerate(test_cases):\n",
    "    print(f\"\\n--- Test {i+1}/{len(test_cases)} ---\")\n",
    "    resp = test_prompt(tc[\"instruction\"], tc.get(\"input\", \"\"))\n",
    "    responses.append(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. Compare Base vs Fine-Tuned (Optional)\n",
    "\n",
    "Load the base model without LoRA to compare outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable LoRA adapter to get base model outputs\n",
    "model.disable_adapter_layers()\n",
    "\n",
    "prompt = \"Explain what transfer learning is and why it's useful.\"\n",
    "print(\"BASE MODEL (no LoRA):\")\n",
    "print(\"-\" * 40)\n",
    "base_response = generate_response(model, tokenizer, prompt, max_new_tokens=200, temperature=0.7)\n",
    "print(base_response)\n",
    "\n",
    "# Re-enable LoRA\n",
    "model.enable_adapter_layers()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"FINE-TUNED MODEL (with LoRA):\")\n",
    "print(\"-\" * 40)\n",
    "ft_response = generate_response(model, tokenizer, prompt, max_new_tokens=200, temperature=0.7)\n",
    "print(ft_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 11. Merge LoRA Weights (Optional)\n",
    "\n",
    "Merge the LoRA adapter into the base model for faster inference without PEFT dependency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING: This requires more VRAM. Only run if you have enough memory.\n",
    "# For RTX 4060 Ti 8GB, this may OOM with 1.5B+ models.\n",
    "\n",
    "MERGE = False  # Set to True to merge\n",
    "\n",
    "if MERGE:\n",
    "    MERGED_DIR = \"./models/merged\"\n",
    "    os.makedirs(MERGED_DIR, exist_ok=True)\n",
    "\n",
    "    print(\"Merging LoRA weights into base model...\")\n",
    "    merged_model = model.merge_and_unload()\n",
    "\n",
    "    print(f\"Saving merged model to {MERGED_DIR}...\")\n",
    "    merged_model.save_pretrained(MERGED_DIR)\n",
    "    tokenizer.save_pretrained(MERGED_DIR)\n",
    "\n",
    "    print(\"Done! Merged model saved.\")\n",
    "    print(f\"Contents:\")\n",
    "    for f in sorted(Path(MERGED_DIR).glob(\"*\")):\n",
    "        size_mb = f.stat().st_size / 1e6\n",
    "        print(f\"  {f.name:40s} {size_mb:8.2f} MB\")\n",
    "else:\n",
    "    print(\"Skipping merge. Set MERGE=True above to merge LoRA into base model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 12. TensorBoard (Optional)\n",
    "\n",
    "View training metrics in TensorBoard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch TensorBoard inline\n",
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir ./logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 13. Custom Dataset Creation\n",
    "\n",
    "Use this section to create your own domain-specific dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataset import create_custom_dataset\n",
    "\n",
    "# Example: Create a small custom dataset\n",
    "custom_instructions = [\n",
    "    \"What is AToM-FM?\",\n",
    "    \"Explain the AToM-FM architecture.\",\n",
    "    \"How does AToM-FM handle multimodal inputs?\",\n",
    "    \"What datasets can AToM-FM be trained on?\",\n",
    "    \"Compare AToM-FM with standard transformer models.\",\n",
    "]\n",
    "\n",
    "custom_outputs = [\n",
    "    \"AToM-FM (Adaptive Transformer of Multimodal Foundation Model) is a foundation model framework designed for adaptive learning across multiple modalities including text, code, and structured data.\",\n",
    "    \"AToM-FM uses a Qwen-based transformer backbone with QLoRA adapters for parameter-efficient fine-tuning. The architecture supports 4-bit quantization for deployment on consumer GPUs.\",\n",
    "    \"AToM-FM processes multimodal inputs through a unified tokenization scheme that maps different data modalities into a shared embedding space before passing them through the transformer layers.\",\n",
    "    \"AToM-FM can be trained on instruction-following datasets like Alpaca, OpenOrca, and domain-specific datasets. It also supports custom JSONL datasets with instruction/input/output format.\",\n",
    "    \"Unlike standard transformers that require full fine-tuning, AToM-FM uses QLoRA to train only 1-3% of parameters while maintaining comparable performance. This makes it accessible on consumer hardware like the RTX 4060 Ti.\",\n",
    "]\n",
    "\n",
    "custom_ds = create_custom_dataset(\n",
    "    instructions=custom_instructions,\n",
    "    outputs=custom_outputs,\n",
    "    save_path=\"./data/processed/custom_atom_fm.jsonl\",\n",
    ")\n",
    "\n",
    "print(f\"Custom dataset created: {len(custom_ds)} samples\")\n",
    "print(f\"Saved to: ./data/processed/custom_atom_fm.jsonl\")\n",
    "print(f\"\\nSample:\")\n",
    "print(custom_ds[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 14. Cleanup & Final VRAM Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Final VRAM usage:\")\n",
    "print_vram_usage()\n",
    "\n",
    "# Uncomment to free GPU memory:\n",
    "# import gc\n",
    "# del model, trainer\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()\n",
    "# print(\"\\nAfter cleanup:\")\n",
    "# print_vram_usage()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"  AToM-FM Training Pipeline Complete!\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
