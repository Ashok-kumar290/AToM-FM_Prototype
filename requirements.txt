# ============================================
# AToM-FM Prototype - Requirements
# Optimized for RTX 4060 Ti (8GB/16GB VRAM)
# ============================================

# --- Core ML Framework ---
torch>=2.1.0
torchvision>=0.16.0
torchaudio>=2.1.0

# --- Hugging Face Ecosystem ---
transformers>=4.37.0
datasets>=2.16.0
accelerate>=0.25.0
tokenizers>=0.15.0
huggingface-hub>=0.20.0

# --- Parameter-Efficient Fine-Tuning ---
peft>=0.7.0
trl>=0.7.6

# --- Quantization (Critical for RTX 4060 Ti) ---
bitsandbytes>=0.41.0
auto-gptq>=0.6.0

# --- Training & Logging ---
wandb>=0.16.0
tensorboard>=2.15.0
evaluate>=0.4.1

# --- Data Processing ---
pandas>=2.1.0
numpy>=1.24.0
scikit-learn>=1.3.0
sentencepiece>=0.1.99

# --- Jupyter Environment ---
jupyter>=1.0.0
jupyterlab>=4.0.0
ipywidgets>=8.1.0
matplotlib>=3.8.0
seaborn>=0.13.0
tqdm>=4.66.0

# --- Configuration ---
pyyaml>=6.0.1
python-dotenv>=1.0.0
omegaconf>=2.3.0

# --- Code Quality ---
black>=23.0.0
ruff>=0.1.0

# --- Flash Attention (optional, significant speedup) ---
# Uncomment if your CUDA setup supports it:
# flash-attn>=2.4.0
